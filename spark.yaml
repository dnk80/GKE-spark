apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi
  namespace: pyfarm
spec:
  type: Scala
  mode: cluster
  image: us-central1-docker.pkg.dev/for-test-418919/spark/spark-gcs:3.5.3
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: "local:///opt/spark-job-access-gcs.py"
  hadoopConf:
  "fs.gs.project.id": "test-gcs-418919"
  "fs.gs.system.bucket": "test-gcs-418919"
  "google.cloud.auth.service.account.enable": "true"
  "google.cloud.auth.service.account.json.keyfile": "/mnt/key.json"
  sparkVersion: "3.5.3"
  sparkConf:
    spark.eventlog.enabled: "true"
  restartPolicy:
    type: Never
  driver:
    cores: 1
    memory: 512m
    labels:
      version: driver
    #serviceAccount: spark
    volumeMounts:
    - name: py-script-vol
      mountPath: /opt
    - name: key-vol
      mountPath: /mnt    
  executor:
    cores: 1
    instances: 2
    memory: 512m
    labels:
      version: executor
    volumeMounts:
    - name: py-script-vol
      mountPath: /opt
    - name: key-vol
      mountPath: /mnt
  volumes:
  - name: py-script-vol
    configMap:
      name: py-script-map
      items:
        - key: spark-job-access-gcs.py
          path: spark-job-access-gcs.py
  - name: key-vol
    secret:
      secretName: gcs-bq
      items:
        - key: comp.json
          path: key.json
